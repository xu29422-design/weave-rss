import { google } from "@ai-sdk/google";
import { createOpenAI } from "@ai-sdk/openai";
import { generateText } from "ai";
import { ANALYST_PROMPT, EDITOR_PROMPT, TLDR_PROMPT } from "./ai-prompts";
import { RawRSSItem } from "./rss-utils";
import { Settings } from "./redis";

/**
 * é€šç”¨çš„ AI æ¨¡å‹åˆå§‹åŒ–å‡½æ•°
 */
function getAIModel(settings: Settings) {
  if (settings.aiProvider === 'google') {
    return {
      model: google("models/gemini-1.5-flash-latest"),
    };
  } else {
    const openai = createOpenAI({
      baseURL: settings.openaiBaseUrl?.trim().replace(/\/+$/, "") || "https://api.openai.com/v1",
      apiKey: settings.openaiApiKey,
    });
    return {
      model: openai.chat(settings.openaiModel || "glm-4-flash"),
    };
  }
}

/**
 * å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•åŒ…è£…å™¨
 */
async function withRetry<T>(
  fn: () => Promise<T>,
  retries = 3,
  delay = 1000
): Promise<T> {
  try {
    return await fn();
  } catch (error: any) {
    // å¦‚æœæ˜¯é€Ÿç‡é™åˆ¶ (429) æˆ–æœåŠ¡å™¨é”™è¯¯ (5xx)ï¼Œåˆ™é‡è¯•
    const isRateLimit = error?.status === 429 || error?.message?.includes("429");
    const isServerError = error?.status >= 500 || error?.message?.includes("500");
    
    if (retries > 0 && (isRateLimit || isServerError)) {
      console.warn(`AI è¯·æ±‚å¤±è´¥ï¼Œæ­£åœ¨é‡è¯• (${retries} æ¬¡å‰©ä½™)... é”™è¯¯: ${error.message}`);
      await new Promise(resolve => setTimeout(resolve, delay));
      return withRetry(fn, retries - 1, delay * 2); // æŒ‡æ•°é€€é¿
    }
    throw error;
  }
}

/**
 * Analyst Agent: åˆ†æå•æ¡æ–°é—» (Map Phase)
 */
export async function analyzeItem(item: RawRSSItem, settings: Settings) {
  const { model } = getAIModel(settings);
  
  const systemPrompt = (settings.analystPrompt || ANALYST_PROMPT) + "\n\nè¯·åŠ¡å¿…åªè¿”å›æ ‡å‡†çš„ JSON å¯¹è±¡ã€‚å³ä½¿å†…å®¹ç®€çŸ­ï¼Œä¹Ÿè¯·åŸºäºæ ‡é¢˜è¿›è¡Œåˆç†æ¨æµ‹å’Œåˆ†ç±»ï¼Œç»™å‡º 1-10 çš„è¯„åˆ†ã€‚ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ï¼Œä¸è¦ä½¿ç”¨ Markdown ä»£ç å—æ ‡ç­¾ã€‚";

  try {
    const { text } = await withRetry(() => generateText({
      model,
      system: systemPrompt,
      prompt: `æ ‡é¢˜: ${item.title}\nå†…å®¹: ${item.contentSnippet || "ï¼ˆå†…å®¹ä¸ºç©ºï¼‰"}\næ¥æº: ${item.sourceName}`,
    } as any));

    const jsonMatch = text.match(/\{[\s\S]*\}/);
    const cleanedText = jsonMatch ? jsonMatch[0] : text;
    const result = JSON.parse(cleanedText);
    
    const hasValidContent = result.summary && result.summary.length > 3 && !result.summary.includes("å†…å®¹ä¸è¶³");
    
    return { 
      title: result.title || item.title,
      summary: hasValidContent ? result.summary : item.title,
      category: result.category || "Other",
      score: hasValidContent ? (result.score || 3) : 3,
      reasoning: result.reasoning || "",
      link: item.link,
      isDeepAnalyzed: hasValidContent // æ ‡è®°æ˜¯å¦ç»è¿‡æ·±åº¦åˆ†æ
    };
  } catch (e: any) {
    console.error("AI ç»“æœè§£æå¤±è´¥æˆ–é‡è¯•è€—å°½:", e.message);
    return {
      title: item.title,
      summary: item.title,
      category: "Other",
      score: 2, // å¤±è´¥æ¡ç›®åˆ†å€¼ç¨ä½
      reasoning: "AI ç¹å¿™ï¼Œå·²è‡ªåŠ¨è·³è¿‡æ·±åº¦åˆ†æ",
      link: item.link,
      isDeepAnalyzed: false
    };
  }
}

/**
 * Editor Agent: æ’°å†™åˆ†ç±»é•¿æ–‡
 */
export async function writeCategorySection(category: string, items: any[], settings: Settings) {
  const { model } = getAIModel(settings);
  const validItems = items.filter(i => i.score > 0 && i.summary !== "è§£æå¤±è´¥");
  
  if (validItems.length === 0) return "(æ•°æ®åŒ…ä¸ºç©ºï¼Œæ²¡æœ‰å†…å®¹)";

  let systemPrompt = settings.editorPrompt || EDITOR_PROMPT(category, validItems.length);
  // å¦‚æœæ˜¯ç”¨æˆ·è‡ªå®šä¹‰æç¤ºè¯ï¼Œæ‰‹åŠ¨æ›¿æ¢å ä½ç¬¦
  if (settings.editorPrompt) {
    systemPrompt = systemPrompt
      .replace(/\$\{category\}/g, category)
      .replace(/\$\{count\}/g, validItems.length.toString());
  }

  const { text } = await generateText({
    model,
    system: systemPrompt,
    prompt: validItems.map(i => `- ${i.title}: ${i.summary} (URL: ${i.link})`).join("\n"),
  } as any);
  return text;
}

/**
 * ç”Ÿæˆå…¨å±€ TL;DR
 */
export async function generateTLDR(allSummaries: string, settings: Settings) {
  if (!allSummaries || (allSummaries.includes("è§£æå¤±è´¥") && allSummaries.length < 20)) {
    return "ğŸŒŸ ä»Šæ—¥ç„¦ç‚¹ ä»Šæ—¥èµ„è®¯æºä¸­æœªå‘ç°é«˜ä»·å€¼æƒ…æŠ¥ã€‚";
  }

  const { model } = getAIModel(settings);
  const systemPrompt = settings.tldrPrompt || TLDR_PROMPT;

  const { text } = await generateText({
    model,
    system: systemPrompt,
    prompt: allSummaries,
  } as any);
  return text;
}
